{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.expanduser(\"~/sentence-benchmark/src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sentence_benchmark.data import load_sts12\n",
    "\n",
    "sts12 = load_sts12(os.path.expanduser(\"~/data/STS/STS12-en-test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 481/481 [00:00<00:00, 141kB/s]\n",
      "Downloading: 100%|██████████| 899k/899k [00:01<00:00, 760kB/s] \n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 560kB/s]\n",
      "Downloading: 100%|██████████| 1.36M/1.36M [00:01<00:00, 734kB/s]\n"
     ]
    }
   ],
   "source": [
    "from simcse.models import ModelInput\n",
    "from typing import TypedDict, List\n",
    "from sentence_benchmark.data import Example\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerBase\n",
    "\n",
    "class TokenizedExample(TypedDict):\n",
    "    example: Example\n",
    "    input1: ModelInput\n",
    "    input2: ModelInput\n",
    "    \n",
    "\n",
    "def preprocess_examples(tokenizer: PreTrainedTokenizerBase, examples: List[Example]) -> List[TokenizedExample]:\n",
    "    tokenized_examples = []\n",
    "    for example in examples:\n",
    "        input1 = tokenizer(example.input[0], return_tensors='pt')\n",
    "        input2 = tokenizer(example.input[1], return_tensors='pt')\n",
    "        tokenized_examples.append({\"example\": example, \"input1\": input1, \"input2\": input2, \"input1_length\": input1[\"input_ids\"].shape[1], \"input2_length\": input2[\"input_ids\"].shape[1]})\n",
    "    return tokenized_examples\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "examples = [example for examples in sts12.values() for example in examples]\n",
    "tokenized_example = preprocess_examples(tokenizer, examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example': Example(input=['the problem likely will mean corrective changes before the shuttle fleet starts flying again .', 'he said the problem needs to be corrected before the space shuttle fleet is cleared to fly again .'], score=4.4),\n",
       " 'input1': {'input_ids': tensor([[    0,   627,   936,   533,    40,  1266, 31378,  1022,   137,     5,\n",
       "          19463,  7620,  2012,  4731,   456,   479,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])},\n",
       " 'input2': {'input_ids': tensor([[    0,   700,    26,     5,   936,   782,     7,    28, 17261,   137,\n",
       "              5,   980, 19463,  7620,    16,  6049,     7,  3598,   456,   479,\n",
       "              2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_example[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b5c851aff8b56ec1836828ebb771b2a727bf37cbe3d9eaebf2edaf4e180d049"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('sentence-benchmark': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
